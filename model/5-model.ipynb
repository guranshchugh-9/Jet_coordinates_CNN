{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb9c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../dataset/dataset.csv')\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Data Loading & Parsing\n",
    "# ---------------------------\n",
    "def parse_signal(signal_str):\n",
    "    \"\"\"Convert complex string to magnitude/phase features\"\"\"\n",
    "    cleaned = signal_str.strip('[]').replace(' ', '')\n",
    "    parts = cleaned.split('),(')\n",
    "    signal = []\n",
    "    for p in parts:\n",
    "        p = p.replace('(', '').replace(')', '')\n",
    "        try:\n",
    "            cmplx = complex(p)\n",
    "            signal.append([abs(cmplx), np.angle(cmplx)])  # Magnitude + Phase\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return np.array(signal[:208])  # Shape: (208, 2)\n",
    "\n",
    "def parse_secret_code(code_str):\n",
    "    \"\"\"Convert secret code string to integer array\"\"\"\n",
    "    return np.array([int(x) for x in code_str.strip('[]').split(', ')])\n",
    "\n",
    "\n",
    "# Parse all columns\n",
    "X_signal = np.array([parse_signal(s) for s in df['received_signal']])  # (15000, 208, 2)\n",
    "X_secret = np.array([parse_secret_code(c) for c in df['secret_code']])  # (15000, 13)\n",
    "y = df[['jet1_x', 'jet1_y', 'jet1_z', 'jet2_x', 'jet2_y', 'jet2_z']].values  # (15000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a27c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------------------------\n",
    "def compute_doppler(signal_2d):\n",
    "    \"\"\"Improved Doppler estimation using phase coherence\"\"\"\n",
    "    phase = signal_2d[:, 1]\n",
    "    unwrapped_phase = np.unwrap(phase)  # Fix phase wrapping issues\n",
    "    return np.std(np.diff(unwrapped_phase))  # Better motion signature\n",
    "\n",
    "X_doppler = np.array([compute_doppler(sig) for sig in X_signal]).reshape(-1, 1)\n",
    "X_secret = np.hstack([X_secret, X_doppler])\n",
    "\n",
    "# Time-Frequency Features\n",
    "def extract_stft_features(signal_2d):\n",
    "    \"\"\"Extract time-frequency features from magnitude channel\"\"\"\n",
    "    from scipy.signal import stft\n",
    "    f, t, Zxx = stft(signal_2d[:, 0], nperseg=32)\n",
    "    return np.log(np.abs(Zxx[:16, :5]) + 1e-8).flatten()  # 80-dim feature\n",
    "\n",
    "X_stft = np.array([extract_stft_features(sig) for sig in X_signal])\n",
    "scaler_stft = StandardScaler()\n",
    "X_stft = scaler_stft.fit_transform(X_stft)\n",
    "X_secret = np.hstack([X_secret, X_stft])  # Now shape=(14+80)=94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb37217d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 208, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0332602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes:\n",
      "Signals: (12000, 208, 2), Codes: (12000, 94), Targets: (12000, 6)\n",
      "\n",
      "Validation shapes:\n",
      "Signals: (1500, 208, 2), Codes: (1500, 94), Targets: (1500, 6)\n",
      "\n",
      "Test shapes:\n",
      "Signals: (1500, 208, 2), Codes: (1500, 94), Targets: (1500, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Data Splitting & Normalization\n",
    "# ---------------------------\n",
    "# First split: 80% train, 20% temp\n",
    "X_sig_train_raw, X_sig_temp_raw, X_sec_train_raw, X_sec_temp_raw, y_train_raw, y_temp_raw = train_test_split(\n",
    "    X_signal, X_secret, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 50% validation, 50% test\n",
    "X_sig_val_raw, X_sig_test_raw, X_sec_val_raw, X_sec_test_raw, y_val_raw, y_test_raw = train_test_split(\n",
    "    X_sig_temp_raw, X_sec_temp_raw, y_temp_raw, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Signal Normalizer (fit on training only)\n",
    "scaler_signal = StandardScaler()\n",
    "X_sig_train_flat = X_sig_train_raw.reshape(-1, 2)\n",
    "scaler_signal.fit(X_sig_train_flat)\n",
    "\n",
    "def scale_and_reshape(X_raw, scaler):\n",
    "    X_flat = X_raw.reshape(-1, 2)\n",
    "    X_scaled = scaler.transform(X_flat)\n",
    "    return X_scaled.reshape(-1, 208, 2)\n",
    "\n",
    "X_sig_train = scale_and_reshape(X_sig_train_raw, scaler_signal)\n",
    "X_sig_val = scale_and_reshape(X_sig_val_raw, scaler_signal)\n",
    "X_sig_test = scale_and_reshape(X_sig_test_raw, scaler_signal)\n",
    "\n",
    "# Secret Code Normalizer\n",
    "scaler_secret = StandardScaler()\n",
    "scaler_secret.fit(X_sec_train_raw)\n",
    "\n",
    "X_sec_train = scaler_secret.transform(X_sec_train_raw)\n",
    "X_sec_val = scaler_secret.transform(X_sec_val_raw)\n",
    "X_sec_test = scaler_secret.transform(X_sec_test_raw)\n",
    "\n",
    "# Target Normalizer\n",
    "scaler_target = StandardScaler()\n",
    "scaler_target.fit(y_train_raw)\n",
    "\n",
    "y_train = scaler_target.transform(y_train_raw)\n",
    "y_val = scaler_target.transform(y_val_raw)\n",
    "y_test = scaler_target.transform(y_test_raw)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Verification\n",
    "# --------------------------------------------------\n",
    "print(\"Training shapes:\")\n",
    "print(f\"Signals: {X_sig_train.shape}, Codes: {X_sec_train.shape}, Targets: {y_train.shape}\")\n",
    "print(\"\\nValidation shapes:\")\n",
    "print(f\"Signals: {X_sig_val.shape}, Codes: {X_sec_val.shape}, Targets: {y_val.shape}\")\n",
    "print(\"\\nTest shapes:\")\n",
    "print(f\"Signals: {X_sig_test.shape}, Codes: {X_sec_test.shape}, Targets: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a08c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4. Data Augmentation\n",
    "# ---------------------------\n",
    "def augment_signal(signal_batch):\n",
    "    \"\"\"Realistic signal augmentation with jamming and Doppler effects\"\"\"\n",
    "    batch_size = signal_batch.shape[0]\n",
    "    \n",
    "    # Variable SNR based on mission phase\n",
    "    snr_levels = np.random.uniform(0.02, 0.1, batch_size)\n",
    "    noise = np.stack([\n",
    "        np.random.normal(0, snr, signal_batch.shape[1:])\n",
    "        for snr in snr_levels\n",
    "    ])\n",
    "    \n",
    "    # Realistic Doppler shifts (jets move at 250-900 km/h)\n",
    "    speed_shifts = np.random.randint(-10, 10, batch_size)\n",
    "    augmented = np.stack([\n",
    "        np.roll(signal_batch[i], shift, axis=0)\n",
    "        for i, shift in enumerate(speed_shifts)\n",
    "    ])\n",
    "    \n",
    "    # Intermittent jamming (5% of samples)\n",
    "    jamming_mask = np.random.choice(\n",
    "        [0, 1], \n",
    "        size=batch_size,\n",
    "        p=[0.95, 0.05]\n",
    "    ).reshape(-1, 1, 1)\n",
    "    \n",
    "    return (augmented + noise) * (1 - jamming_mask) + jamming_mask * np.random.normal(0, 0.5, signal_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5cf1f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling1D, Dropout, Embedding, Dot, Softmax\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "# ---------------------------\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    \"\"\"Custom loss with higher weight for altitude (z) coordinates\"\"\"\n",
    "    weights = tf.constant([1.0, 1.0, 2.0, 1.0, 1.0, 2.0])  # Double weight for z-coordinates\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred) * weights)\n",
    "\n",
    "# Signal Branch (Optimized CNN)\n",
    "signal_input = Input(shape=(208, 2), name='signal_input')\n",
    "x = layers.Conv1D(64, 5, activation='relu', padding='same')(signal_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(2)(x)  # 104 steps\n",
    "x = layers.Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer='l2')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Secret Code Branch with Interaction\n",
    "code_input = Input(shape=(94,), name='code_input')\n",
    "y = layers.Dense(128, activation='relu')(code_input)\n",
    "y = layers.BatchNormalization()(y)\n",
    "y = layers.Dense(256, activation='relu')(y)  # Match CNN output size\n",
    "\n",
    "# Feature Interaction\n",
    "code_repeated = layers.RepeatVector(128)(y)  # Match CNN output size\n",
    "# Feature Interaction\n",
    "x = layers.Multiply()([x, y])  # Direct multiplication of matching shapes  # Attention-like interaction\n",
    "\n",
    "# Fusion\n",
    "merged = layers.concatenate([x, y])\n",
    "merged = layers.BatchNormalization()(merged)\n",
    "\n",
    "# Final Layers\n",
    "z = layers.Dense(512, activation='relu', kernel_regularizer='l2')(merged)\n",
    "z = layers.BatchNormalization()(z)\n",
    "z = layers.Dropout(0.3)(z)\n",
    "z = layers.Dense(256, activation='relu', kernel_regularizer='l2')(z)\n",
    "outputs = layers.Dense(6)(z)\n",
    "\n",
    "# Compile with Correct LR\n",
    "model = Model(inputs=[signal_input, code_input], outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=3e-3),\n",
    "    loss=weighted_mse,\n",
    "    metrics=['mae']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7903dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 6s 55ms/step - loss: 12.4831 - mae: 1.1252 - val_loss: 10.9843 - val_mae: 0.8697 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 9.8515 - mae: 0.9425 - val_loss: 8.1946 - val_mae: 0.8666 - lr: 6.8000e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 6.7296 - mae: 0.8569 - val_loss: 5.3282 - val_mae: 0.8564 - lr: 0.0013\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 4.1384 - mae: 0.8270 - val_loss: 3.1592 - val_mae: 0.8283 - lr: 0.0018\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 2.5454 - mae: 0.8123 - val_loss: 2.0695 - val_mae: 0.8132 - lr: 0.0024\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.7977 - mae: 0.7999 - val_loss: 1.5995 - val_mae: 0.8070 - lr: 0.0030\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.4856 - mae: 0.7901 - val_loss: 1.4039 - val_mae: 0.7905 - lr: 0.0030\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.3624 - mae: 0.7848 - val_loss: 1.3253 - val_mae: 0.7845 - lr: 0.0030\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 1.3026 - mae: 0.7809 - val_loss: 1.2839 - val_mae: 0.7754 - lr: 0.0030\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.2719 - mae: 0.7774 - val_loss: 1.2970 - val_mae: 0.7846 - lr: 0.0029\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 1.2494 - mae: 0.7748 - val_loss: 1.2561 - val_mae: 0.7740 - lr: 0.0029\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 1.2325 - mae: 0.7725 - val_loss: 1.2566 - val_mae: 0.7721 - lr: 0.0029\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 1.2193 - mae: 0.7689 - val_loss: 1.2377 - val_mae: 0.7707 - lr: 0.0028\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 6s 59ms/step - loss: 1.1989 - mae: 0.7658 - val_loss: 1.2588 - val_mae: 0.7770 - lr: 0.0028\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 1.2005 - mae: 0.7661 - val_loss: 1.2471 - val_mae: 0.7723 - lr: 0.0027\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 1.1873 - mae: 0.7616 - val_loss: 1.2479 - val_mae: 0.7698 - lr: 5.2981e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 6s 63ms/step - loss: 1.1738 - mae: 0.7575 - val_loss: 1.2360 - val_mae: 0.7738 - lr: 0.0026\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 1.1621 - mae: 0.7548 - val_loss: 1.2525 - val_mae: 0.7697 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 5s 53ms/step - loss: 1.1525 - mae: 0.7515 - val_loss: 1.2843 - val_mae: 0.7788 - lr: 0.0024\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 1.1400 - mae: 0.7471 - val_loss: 1.2453 - val_mae: 0.7695 - lr: 4.6776e-04\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 6s 59ms/step - loss: 1.1292 - mae: 0.7440 - val_loss: 1.2561 - val_mae: 0.7689 - lr: 0.0022\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 1.1209 - mae: 0.7403 - val_loss: 1.2806 - val_mae: 0.7752 - lr: 0.0022\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 1.1098 - mae: 0.7353 - val_loss: 1.2780 - val_mae: 0.7769 - lr: 4.1238e-04\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 1.0974 - mae: 0.7329 - val_loss: 1.2845 - val_mae: 0.7742 - lr: 0.0020\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.0796 - mae: 0.7267 - val_loss: 1.3009 - val_mae: 0.7757 - lr: 0.0019\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.0661 - mae: 0.7213 - val_loss: 1.3131 - val_mae: 0.7788 - lr: 3.5209e-04\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 1.0495 - mae: 0.7158 - val_loss: 1.3159 - val_mae: 0.7751 - lr: 0.0017\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Training Strategy\n",
    "# ---------------------------\n",
    "# Learning Rate Schedule\n",
    "class WarmupCosineDecay:\n",
    "    def __init__(self, warmup_epochs, total_epochs):\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.total_epochs = total_epochs\n",
    "        \n",
    "    def __call__(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            return 1e-4 + (3e-3 - 1e-4) * epoch / self.warmup_epochs\n",
    "        return 0.5 * 3e-3 * (\n",
    "            1 + np.cos(np.pi * (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs))\n",
    "        )\n",
    "\n",
    "# Callbacks\n",
    "warmup_lr = LearningRateScheduler(WarmupCosineDecay(5, 50))\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Create noisy training data\n",
    "X_sig_train_noisy = augment_signal(X_sig_train)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=[X_sig_train_noisy, X_sec_train],\n",
    "    y=y_train,\n",
    "    validation_data=([X_sig_val, X_sec_val], y_val),\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop, reduce_lr, warmup_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42798fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Test MSE: 1.2665\n",
      "Normalized Test MAE: 0.7802\n",
      "47/47 [==============================] - 0s 5ms/step\n",
      "\n",
      "Real-World MAE: 6079.87 meters\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(\n",
    "    [X_sig_test, X_sec_test],\n",
    "    y_test,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"Normalized Test MSE: {test_loss:.4f}\")\n",
    "print(f\"Normalized Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_pred_norm = model.predict([X_sig_test, X_sec_test])\n",
    "y_pred_real = scaler_target.inverse_transform(y_pred_norm)\n",
    "y_test_real = scaler_target.inverse_transform(y_test)\n",
    "\n",
    "# Real-world metrics\n",
    "real_mae = np.mean(np.abs(y_pred_real - y_test_real))\n",
    "print(f\"\\nReal-World MAE: {real_mae:.2f} meters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
