{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb9c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../dataset/dataset.csv')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1.1 Signal Decoding\n",
    "# --------------------------------------------------\n",
    "def parse_signal(signal_str):\n",
    "    cleaned = signal_str.strip('[]').replace(' ', '')\n",
    "    parts = cleaned.split('),(')\n",
    "    complex_samples = []\n",
    "    for p in parts:\n",
    "        p = p.replace('(', '').replace(')', '')\n",
    "        try:\n",
    "            # Convert directly to complex number\n",
    "            complex_samples.append(complex(p))\n",
    "        except ValueError:\n",
    "            # Skip any invalid entries\n",
    "            continue\n",
    "    return np.array(complex_samples[:208])\n",
    "\n",
    "# Apply to all rows\n",
    "X_signal = np.array([parse_signal(s) for s in df['received_signal']])\n",
    "# print(X_signal[:1])\n",
    "X_signal = np.hstack([X_signal.real, X_signal.imag])  # (15000, 416)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1.2 Secret Code Handling\n",
    "# --------------------------------------------------\n",
    "def parse_secret_code(code_str):\n",
    "    return np.array([int(x) for x in code_str.strip('[]').split(', ')])\n",
    "\n",
    "X_secret = np.array([parse_secret_code(c) for c in df['secret_code']])  # (15000, 13)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1.3 Target Preparation\n",
    "# --------------------------------------------------\n",
    "y = df[['jet1_x', 'jet1_y', 'jet1_z', \n",
    "        'jet2_x', 'jet2_y', 'jet2_z']].values  # (15000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9e3172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11931579  0.85771666 -1.33474694 -0.50391545 -2.29890648 -2.36311255\n",
      "  -1.73337179 -2.09075436 -1.68077154 -2.06851403 -2.23007812 -1.68373539\n",
      "  -0.99208445 -1.52579929 -2.13198495 -1.542111   -1.572531   -1.17894242\n",
      "  -0.43579253 -0.37435658 -0.20439189 -0.34568808 -0.3036721   0.78714854\n",
      "  -0.13114397  0.91876952  0.59695031  0.46554019  0.30731446  0.57871762\n",
      "   1.3063269   1.32965779  1.84256292  2.62761689  3.8078487   2.76445951\n",
      "   2.48637366  2.88149825  2.38199167  2.72596637  1.39522053  0.8044313\n",
      "   0.23753253 -0.8312159  -2.08004069 -2.24298221 -2.99989836 -3.15122902\n",
      "  -3.34715525 -3.41449118 -1.9398927  -2.12972652 -1.46899167 -0.57031672\n",
      "  -0.59802137 -0.68256009  0.22612962  0.72654863 -0.07467601 -0.28339311\n",
      "  -1.24302304 -0.46743044 -1.8572562  -2.77289709 -3.06969035 -3.11564192\n",
      "  -3.84457788 -3.57200481 -3.62208702 -3.10760311 -2.81848032 -1.19532471\n",
      "  -0.52973206  1.028434    2.24372655  3.21794968  3.74768431  4.09193022\n",
      "   3.67424067  1.20070218  0.9215773  -0.32409149 -0.95804282 -1.53625975\n",
      "  -1.6691226  -1.44810181 -0.98797122 -1.25838309 -0.31710668  0.32033606\n",
      "   0.01722652  0.01029079 -0.7296314  -1.06291356 -1.83280567 -2.35673147\n",
      "  -1.26003689 -1.80362926 -0.57888357  0.12816169  1.92247659  3.17354318\n",
      "   4.5784564   4.6799711   3.99575245  4.3601979   4.35067019  3.98141323\n",
      "   3.11049737  2.52820087  3.05545169  1.62905881  1.72640733  1.87947046\n",
      "   2.43117159  1.65759689  1.88984898  1.53172444  0.66033044  0.5075424\n",
      "   0.37956633 -0.2255492  -0.33895737  0.28309368 -1.43836252 -0.62426709\n",
      "  -1.35390063 -1.59116717 -0.90522305 -1.88345831 -2.60201123 -2.41085092\n",
      "  -2.82657584 -2.71199095 -2.58669605 -3.00701459 -4.3897203  -3.70122355\n",
      "  -3.33463868 -3.22380333 -3.916825   -3.11374581 -2.73327251 -2.3006711\n",
      "  -1.64425923 -0.4590607   0.72825052  0.68201515  0.60472815  2.02351268\n",
      "   1.32740075  1.40317075  1.09965867  1.06118701 -0.1465709  -0.28398909\n",
      "  -0.6628539  -0.43622468 -1.00519143 -0.37331504 -0.51596518  0.06006327\n",
      "   0.88926361  0.68664113  1.61444382  2.47864035  2.62381389  3.33445836\n",
      "   3.6137174   4.36846922  4.62278869  3.49752771  4.64932199  2.81880775\n",
      "   2.00836369  0.93765139  0.75377888 -0.2639077  -1.53247703 -2.00700008\n",
      "  -1.97609364 -2.13680349 -1.08359135 -1.55614644 -0.37652617 -0.29465723\n",
      "  -0.03468595 -0.35313954 -0.58812493 -0.61252843 -0.3860559  -0.36061119\n",
      "  -0.29311999  0.17632541  0.88470189  1.66805717  2.30765629  2.74166994\n",
      "   2.59701579  2.62563671  1.06425552  0.99663042  0.36812856 -0.80902182\n",
      "  -1.30788815 -2.39722722 -3.07569212 -2.65028829 -0.18838487 -0.56765235\n",
      "  -0.11720316 -0.81051995 -0.68204147 -0.48197614 -0.74450004  0.18309591\n",
      "   0.52066226  0.24628794  0.6992717   0.90507247  0.15223365  0.78545085\n",
      "   1.08187145  1.16016919  1.51293791  1.09127687  1.50406356  2.38332379\n",
      "   1.86631131  1.99013825  2.35893882  1.76130989  1.94498267  1.97959009\n",
      "   1.92890914  1.51874787  1.70770458  1.75845775  1.61684064  1.79340078\n",
      "   1.85777249  2.22575113  1.06173948  1.54385667  0.6689708   0.44325394\n",
      "   0.21341432 -0.66803755 -0.12616764 -0.34332671  0.32838168  0.25308863\n",
      "   1.06603248  0.77849702  2.19599112  2.20768538  2.93501197  3.52318242\n",
      "   4.27801135  3.11955596  3.34953084  3.34916402  2.71755891  1.04352208\n",
      "   1.3738256  -0.34002019 -0.74490571 -1.44017658 -2.16126018 -2.64220136\n",
      "  -2.43815361 -3.42507122 -3.48005999 -4.12814732 -2.82440855 -2.55333208\n",
      "  -1.81809151 -1.02217693 -1.10669803 -0.4447862  -0.29535984 -0.12027711\n",
      "  -0.24141722 -0.90435814 -2.00444718 -2.67015074 -1.88175762 -1.88238593\n",
      "  -1.15164593 -0.2034259   0.96820915  0.94611621  3.10543414  3.23520547\n",
      "   3.52437337  3.47955697  1.82439869  0.02492767 -0.67400828 -2.31183672\n",
      "  -3.13014024 -3.43283864 -4.29685135 -2.90088534 -1.66464684 -1.52147839\n",
      "  -0.42180236  0.69069216  0.79614629  1.93289929  1.40895908  1.30984009\n",
      "   0.51159665 -0.02677601  0.95502702 -1.17667556 -1.5893416  -0.7366367\n",
      "  -0.96017523 -0.99551814 -1.79962854 -1.96444454 -1.53194341 -1.39369456\n",
      "  -2.81787608 -2.67572651 -3.08588146 -3.19179835 -2.85769526 -3.7155524\n",
      "  -2.86765949 -3.07142002 -3.16910984 -3.25214972 -2.91031039 -1.8350141\n",
      "  -2.44714989 -1.63730054 -1.84317311 -1.29922807 -1.52574044 -1.19964185\n",
      "  -1.46236608 -0.49983721 -0.5436439  -0.53469125 -0.46379591  0.85333731\n",
      "   0.68529192  0.61078726  0.59828287  1.62314433  0.54235633  0.20550211\n",
      "  -0.67042051 -1.68631908 -1.96955082 -3.25558984 -2.25837018 -3.91343537\n",
      "  -3.97848531 -5.12453989 -4.55743789 -3.42475115 -4.05982839 -2.57708551\n",
      "  -2.11800591 -2.46751595 -1.06988631 -0.42778041  0.54171981  0.70981591\n",
      "   1.07426921  1.27139113  1.68430661  0.92427009  1.22276525  1.17387562\n",
      "   0.14652152 -0.04028132 -0.29806303 -0.11487097 -0.37377127 -1.06512202\n",
      "  -0.22955424  1.6764595   1.07481063  1.80379891  1.91655374  2.61117075\n",
      "   2.17414857  1.76724152  0.90616714  0.49148887 -1.17238118 -2.20973401\n",
      "  -2.53738228 -2.71637158 -2.54183832 -1.88501311 -1.58101392 -0.4404084\n",
      "  -0.17819067  0.98515569  1.37786876  1.81376772  1.53402393  1.5796115\n",
      "   0.50108234  0.21271581  0.75656125  0.13208086 -0.22734994  1.35653706\n",
      "   0.09700217  0.68696531]]\n"
     ]
    }
   ],
   "source": [
    "print(X_signal[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5b0477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11931579,  0.85771666, -1.33474694, ...,  1.35653706,\n",
       "         0.09700217,  0.68696531],\n",
       "       [-0.035028  , -0.9321786 , -1.07103858, ..., -0.31218129,\n",
       "        -0.86626219, -1.67845885],\n",
       "       [-0.01784629, -0.30454525, -0.63100547, ...,  2.48600477,\n",
       "         2.57460476,  2.38237365],\n",
       "       ...,\n",
       "       [ 0.18681767,  0.2127872 , -0.10902881, ..., -1.86084518,\n",
       "        -2.68116411, -3.5353162 ],\n",
       "       [ 0.28481301,  1.10820823,  1.38517485, ...,  1.33907262,\n",
       "         1.06573864,  0.82789565],\n",
       "       [ 0.19803341,  0.78227132,  0.95982124, ...,  1.25057382,\n",
       "         1.13393457,  1.30820358]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb37217d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 416)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0332602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes: (12000, 208, 2) (12000, 13) (12000, 6)\n",
      "Validation shapes: (1500, 208, 2) (1500, 13) (1500, 6)\n",
      "Test shapes: (1500, 208, 2) (1500, 13) (1500, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2.1 I/Q Signal Engineering (CNN Input)\n",
    "# --------------------------------------------------\n",
    "# Normalize signal features column-wise\n",
    "scaler_signal = StandardScaler()\n",
    "X_signal_normalized = scaler_signal.fit_transform(X_signal)  # (15000, 416)\n",
    "\n",
    "# Reshape for CNN (samples, timesteps, channels)\n",
    "# Assuming original signal had 208 complex samples → 208 timesteps × 2 channels (real/imag)\n",
    "X_signal_reshaped = X_signal_normalized.reshape(-1, 208, 2)  # (15000, 208, 2)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2.2 Secret Code Normalization (Dense Input)\n",
    "# --------------------------------------------------\n",
    "scaler_secret = StandardScaler()\n",
    "X_secret_normalized = scaler_secret.fit_transform(X_secret)  # (15000, 13)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2.3 Target Normalization\n",
    "# --------------------------------------------------\n",
    "scaler_target = StandardScaler()\n",
    "y_normalized = scaler_target.fit_transform(y)  # (15000, 6)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Data Splitting (Keep Branches Separate)\n",
    "# --------------------------------------------------\n",
    "# Split signal and secret code data separately but consistently\n",
    "# First split: 80% train, 20% temp\n",
    "X_sig_train, X_sig_temp, X_sec_train, X_sec_temp, y_train, y_temp = train_test_split(\n",
    "    X_signal_reshaped,  # (15000, 208, 2)\n",
    "    X_secret_normalized,  # (15000, 13)\n",
    "    y_normalized,  # (15000, 6)\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 50% validation, 50% test (of the 20% temp)\n",
    "X_sig_val, X_sig_test, X_sec_val, X_sec_test, y_val, y_test = train_test_split(\n",
    "    X_sig_temp, \n",
    "    X_sec_temp, \n",
    "    y_temp, \n",
    "    test_size=0.5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training shapes:\", X_sig_train.shape, X_sec_train.shape, y_train.shape)\n",
    "print(\"Validation shapes:\", X_sig_val.shape, X_sec_val.shape, y_val.shape)\n",
    "print(\"Test shapes:\", X_sig_test.shape, X_sec_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38110ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " radar_signal (InputLayer)   [(None, 208, 2)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 208, 32)              224       ['radar_signal[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 104, 32)              0         ['conv1d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 104, 64)              6208      ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 52, 64)               0         ['conv1d_1[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " secret_code (InputLayer)    [(None, 13)]                 0         []                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 3328)                 0         ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   896       ['secret_code[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  426112    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   2080      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " intel_fusion (Concatenate)  (None, 160)                  0         ['dense[0][0]',               \n",
      "                                                                     'dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64)                   10304     ['intel_fusion[0][0]']        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 32)                   2080      ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 6)                    198       ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 448102 (1.71 MB)\n",
      "Trainable params: 448102 (1.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3.1 Dual Input Branches\n",
    "# --------------------------------------------------\n",
    "# Branch 1: Radar Signal Processor (CNN)\n",
    "signal_input = Input(shape=(208, 2), name=\"radar_signal\")  # (timesteps, channels)\n",
    "x = Conv1D(32, 3, activation=\"relu\", padding=\"same\")(signal_input)\n",
    "x = MaxPooling1D(2)(x)  # Output: (104, 32)\n",
    "x = Conv1D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling1D(2)(x)  # Output: (52, 64)\n",
    "x = Flatten()(x)         # Output: (52*64 = 3328)\n",
    "x = Dense(128, activation=\"relu\")(x)  # Compress to 128 features\n",
    "\n",
    "# Branch 2: Code Breaker (Dense Network)\n",
    "code_input = Input(shape=(13,), name=\"secret_code\")\n",
    "y = Dense(64, activation=\"relu\")(code_input)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3.2 Combined Strike Force\n",
    "# --------------------------------------------------\n",
    "merged = concatenate([x, y], name=\"intel_fusion\")  # 128 + 32 = 160 features\n",
    "z = Dense(64, activation=\"relu\")(merged)\n",
    "z = Dense(32, activation=\"relu\")(z)\n",
    "outputs = Dense(6, activation=\"linear\")(z)  # 6 coordinates\n",
    "\n",
    "# --------------------------------------------------\n",
    "# War Machine Assembly\n",
    "# --------------------------------------------------\n",
    "model = Model(inputs=[signal_input, code_input], outputs=outputs)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Weapon Calibration (Compilation)\n",
    "# --------------------------------------------------\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"mse\",  # Mean Squared Error for coordinates\n",
    "    metrics=[\"mae\"]  # Monitor Mean Absolute Error\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Reconnaissance Report (Model Summary)\n",
    "# --------------------------------------------------\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e811e23",
   "metadata": {},
   "source": [
    "1. Why ReLU in Hidden Layers?\n",
    "ReLU (Rectified Linear Unit) is the default activation for hidden layers\n",
    "\n",
    "2. Linear Activation in the Final Layer?\n",
    "The final layer (Dense(6, activation=\"linear\") uses linear activation because:\n",
    "\n",
    "Regression Task:\n",
    "You’re predicting 6 continuous coordinates (like x, y, z positions). A linear activation outputs unbounded values, which is ideal for regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950de1a",
   "metadata": {},
   "source": [
    "### 1. CNN Branch: The Tea Brewing Process  \n",
    "**Input Signal** = A pot of tea with:  \n",
    "- **208 tea leaves** (timesteps)  \n",
    "- **2 types of leaves** (channels: e.g., *sweetness* and *bitterness*).  \n",
    "\n",
    "#### Step 1: First Strainer (`Conv1D` with 32 filters)  \n",
    "- You use **32 unique strainers** (filters) to pour the tea through.  \n",
    "- Each strainer has a **window size of 3 leaves** (`kernel_size=3`) and mixes both leaf types (channels).  \n",
    "- **Output**: 32 distinct \"flavors\" of tea (feature maps), e.g., bitterness spikes.  \n",
    "\n",
    "#### Step 2: Concentrate the Tea (`MaxPooling1D`)  \n",
    "- Boil down the tea to **half its volume** (104 timesteps), keeping only the strongest flavors (max values).  \n",
    "\n",
    "#### Step 3: Second Strainer (`Conv1D` with 64 filters)  \n",
    "- Use **64 finer strainers** to detect complex flavor combinations (e.g., *bitter-sweet oscillations*).  \n",
    "- **Output**: 64 refined teas.  \n",
    "- **Concentrate again** (`MaxPooling1D` → 52 timesteps).  \n",
    "\n",
    "#### Step 4: Flatten & Compress (`Dense` Layer)  \n",
    "- **Flatten**: Pour all 64 teas into a single stream (3328 features).  \n",
    "- **`Dense(128)`**: Reduce to **128 essential flavors** (critical for mixing with the code branch).  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Code Branch: Secret Spice Preparation  \n",
    "**Input Code** = A **13-ingredient secret spice mix**.  \n",
    "- **`Dense(64)`**: Extract 64 aromatic notes (e.g., *cinnamon, nutmeg*).  \n",
    "- **`Dense(32)`**: Refine to **32 potent spices** (e.g., *smoky, earthy*).  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Fusion: Mixing Tea & Spices  \n",
    "- **Concatenate**: Combine the **128 tea flavors** and **32 spices** → 160-dimensional \"super-blend.\"  \n",
    "- **`Dense(64 → 32)`**: Harmonize the mixture into a balanced brew.  \n",
    "- **Output Layer (`Dense(6)`)**: Predict **6 coordinates** (e.g., perfect tea temperature, sweetness).  \n",
    "\n",
    "---\n",
    "\n",
    "### 🚨 What the Tea Analogy Misses  \n",
    "1. **Learning Weights**:  \n",
    "   - Filters (strainers) **adapt** during training (unlike static strainers).  \n",
    "\n",
    "2. **Non-Linear Activation (`ReLU`)**:  \n",
    "   - Acts like a \"flavor enhancer,\" removing bland/negative tastes (values < 0).  \n",
    "\n",
    "3. **Optimizer & Loss Function**:  \n",
    "   - `Adam` = **master brewer** adjusting strainers/spices to minimize errors (`MSE` loss).  \n",
    "\n",
    "4. **Concatenation of Branches**:  \n",
    "   - Mixing radar signals (tea) + secret codes (spices) has no direct tea analogy.  \n",
    "\n",
    "5. **Training Process**:  \n",
    "   - Iterative refinement over trials (epochs) with `EarlyStopping` to avoid over-brewing (overfitting).  \n",
    "\n",
    "---\n",
    "\n",
    "### 🍵 Final Takeaway  \n",
    "The tea analogy simplifies **hierarchical feature extraction** and **fusion**, but real neural networks add:  \n",
    "- Adaptability (dynamic strainers),  \n",
    "- Non-linear transformations (`ReLU`),  \n",
    "- Mathematical optimization (`Adam`).  \n",
    "\n",
    "The code is a **self-adjusting recipe**—not a fixed kitchen process! 🔮"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0caf8",
   "metadata": {},
   "source": [
    "## 1. The Two Spy Agencies (Dual Inputs)\n",
    "## James Bond, Jason Bourne\n",
    "\n",
    "## 2. How James Bond Works (CNN Operations)\n",
    "\n",
    "### a. Conv1D Layer (32 filters, kernel_size=3)\n",
    "- **Imagine Bond has 32 special glasses (filters)**\n",
    "- **Each glass looks at 3 time-steps at a time** (kernel_size=3)\n",
    "- **\"Same\" padding** = Adds invisible zeros at edges so Bond doesn't miss end signals\n",
    "- **Relu activation** = \"If you see something interesting, shout louder!\"\n",
    "\n",
    "### b. MaxPooling1D (2)\n",
    "- **\"Only remember the most important clue every 2 steps\"**\n",
    "- Reduces data from 208 → 104 steps\n",
    "- **Repeat with bigger glasses:**\n",
    "  - Now 64 filters (better pattern recognition)\n",
    "  - Reduces 104 → 52 steps\n",
    "\n",
    "### c. Flatten\n",
    "- Takes all clues (52 steps × 64 filters) = 3328 pieces of intel\n",
    "- Puts them in one long list\n",
    "\n",
    "### d. Dense(128)\n",
    "- Condenses 3328 pieces → 128 most important clues\n",
    "\n",
    "---\n",
    "\n",
    "## 3. How Jason Bourne Works (Code Breaking)\n",
    "**Secret Code Processing:**\n",
    "1. `Dense(64)`: Turns 13 digits → 64 hidden patterns\n",
    "2. `Dense(32)`: Condenses to 32 ultimate code secrets\n",
    "\n",
    "---\n",
    "\n",
    "## 4. The Team-Up (Concatenation)\n",
    "- Combines Bond's 128 clues + Bourne's 32 secrets = **160 combined intel**\n",
    "- Works together through final layers:\n",
    "  - `Dense(64)`: Team discussion to align findings\n",
    "  - `Dense(32)`: Final strategy meeting\n",
    "  - `Output(6)`: 3D coordinates (x,y,z + maybe velocity?)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Why This Works?\n",
    "\n",
    "### CNN Advantages for Radar:\n",
    "- **Kernel** = Pattern detector (small time-window scanner)\n",
    "- **Pooling** = \"Don't get distracted by noise\"\n",
    "- Learns **hierarchical patterns**: small details → big picture\n",
    "\n",
    "### Secret Code Handling:\n",
    "- Dense layers find relationships between code digits\n",
    "- Even if code is scrambled, network learns to decode\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Training Setup\n",
    "- **Adam Optimizer**: Smart learning rate adjustment\n",
    "- **MSE Loss**: Punishes big coordinate errors more than small ones\n",
    "- **MAE Metric**: Tracks average error distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1aace45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Revised Branch 1: Radar Signal Processor (with Dropout)\n",
    "# --------------------------------------------------\n",
    "signal_input = Input(shape=(208, 2))\n",
    "x = Conv1D(32, 3, activation='relu')(signal_input)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # 50% dropout to break enemy decoy patterns\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Revised Branch 2: Code Breaker (with Dropout)\n",
    "# --------------------------------------------------\n",
    "code_input = Input(shape=(13,))\n",
    "y = Dense(64, activation='relu')(code_input)\n",
    "y = Dense(32, activation='relu')(y)\n",
    "y = Dropout(0.3)(y)  # 30% dropout to counter code spoofing\n",
    "\n",
    "# Merge and final layers remain unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07838fc4",
   "metadata": {},
   "source": [
    "1. Radar Signal Branch (Tea Brewing with Dropout)\n",
    "After extracting 128 essential flavors (Dense(128)):\n",
    "\n",
    "Dropout(0.5): Before mixing with the code spices, randomly block 50% of the tea flavors (e.g., sweetness, bitterness) in each training batch.\n",
    "\n",
    "Why? Forces the team to learn multiple ways to make good tea, even if half the flavors are missing.\n",
    "\n",
    "2. Code Branch (Spice Preparation with Dropout)\n",
    "After refining 32 spices (Dense(32)):\n",
    "\n",
    "Dropout(0.3): Randomly remove 30% of the spices (e.g., cinnamon, nutmeg) in each batch.\n",
    "\n",
    "Why? Ensures the recipe doesn’t depend too much on any single spice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0fccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    patience=10,          # Abort if no improvement for 10 epochs\n",
    "    restore_best_weights=True,  # Revert to best-known parameters\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42798fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.0107 (Normalized)\n",
      "Test MAE: 0.8672 (Normalized)\n",
      "47/47 [==============================] - 0s 3ms/step\n",
      "Real-World MAE: 8222.47 meters\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(  \n",
    "    [X_sig_test, X_sec_test],   \n",
    "    y_test,  \n",
    "    verbose=0  \n",
    ")  \n",
    "print(f\"Test MSE: {test_loss:.4f} (Normalized)\")  \n",
    "print(f\"Test MAE: {test_mae:.4f} (Normalized)\")  \n",
    "\n",
    "# Inverse-transform for real-world error  \n",
    "y_pred_normalized = model.predict([X_sig_test, X_sec_test])  \n",
    "y_pred_real = scaler_target.inverse_transform(y_pred_normalized)  \n",
    "y_test_real = scaler_target.inverse_transform(y_test)  \n",
    "\n",
    "# Calculate real-world MAE  \n",
    "mae_real = np.mean(np.abs(y_pred_real - y_test_real))  \n",
    "print(f\"Real-World MAE: {mae_real:.2f} meters\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
