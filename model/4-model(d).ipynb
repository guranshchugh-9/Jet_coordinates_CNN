{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb9c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../dataset/dataset.csv')\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Data Loading & Parsing\n",
    "# ---------------------------\n",
    "def parse_signal(signal_str):\n",
    "    \"\"\"Convert complex string to magnitude/phase features\"\"\"\n",
    "    cleaned = signal_str.strip('[]').replace(' ', '')\n",
    "    parts = cleaned.split('),(')\n",
    "    signal = []\n",
    "    for p in parts:\n",
    "        p = p.replace('(', '').replace(')', '')\n",
    "        try:\n",
    "            cmplx = complex(p)\n",
    "            signal.append([abs(cmplx), np.angle(cmplx)])  # Magnitude + Phase\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return np.array(signal[:208])  # Shape: (208, 2)\n",
    "\n",
    "def parse_secret_code(code_str):\n",
    "    \"\"\"Convert secret code string to integer array\"\"\"\n",
    "    return np.array([int(x) for x in code_str.strip('[]').split(', ')])\n",
    "\n",
    "\n",
    "# Parse all columns\n",
    "X_signal = np.array([parse_signal(s) for s in df['received_signal']])  # (15000, 208, 2)\n",
    "X_secret = np.array([parse_secret_code(c) for c in df['secret_code']])  # (15000, 13)\n",
    "X_secret_shifted = X_secret + 1  # Now values are 0-1000\n",
    "input_dim = np.max(X_secret_shifted) + 1  # 1001 for your data\n",
    "y = df[['jet1_x', 'jet1_y', 'jet1_z', 'jet2_x', 'jet2_y', 'jet2_z']].values  # (15000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0332602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes:\n",
      "Signals: (12000, 208, 2), Codes: (12000, 13), Targets: (12000, 6)\n",
      "\n",
      "Validation shapes:\n",
      "Signals: (1500, 208, 2), Codes: (1500, 13), Targets: (1500, 6)\n",
      "\n",
      "Test shapes:\n",
      "Signals: (1500, 208, 2), Codes: (1500, 13), Targets: (1500, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Data Splitting & Normalization\n",
    "# ---------------------------\n",
    "# First split: 80% train, 20% temp\n",
    "X_sig_train_raw, X_sig_temp_raw, X_sec_train_raw, X_sec_temp_raw, y_train_raw, y_temp_raw = train_test_split(\n",
    "    X_signal, X_secret_shifted , y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 50% validation, 50% test\n",
    "X_sig_val_raw, X_sig_test_raw, X_sec_val_raw, X_sec_test_raw, y_val_raw, y_test_raw = train_test_split(\n",
    "    X_sig_temp_raw, X_sec_temp_raw, y_temp_raw, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Signal Normalizer (fit on training only)\n",
    "scaler_signal = StandardScaler()\n",
    "X_sig_train_flat = X_sig_train_raw.reshape(-1, 2)\n",
    "scaler_signal.fit(X_sig_train_flat)\n",
    "\n",
    "def scale_and_reshape(X_raw, scaler):\n",
    "    X_flat = X_raw.reshape(-1, 2)\n",
    "    X_scaled = scaler.transform(X_flat)\n",
    "    return X_scaled.reshape(-1, 208, 2)\n",
    "\n",
    "X_sig_train = scale_and_reshape(X_sig_train_raw, scaler_signal)\n",
    "X_sig_val = scale_and_reshape(X_sig_val_raw, scaler_signal)\n",
    "X_sig_test = scale_and_reshape(X_sig_test_raw, scaler_signal)\n",
    "\n",
    "# Secret Code Normalizer\n",
    "scaler_secret = StandardScaler()\n",
    "scaler_secret.fit(X_sec_train_raw)\n",
    "\n",
    "X_sec_train = scaler_secret.transform(X_sec_train_raw)\n",
    "X_sec_val = scaler_secret.transform(X_sec_val_raw)\n",
    "X_sec_test = scaler_secret.transform(X_sec_test_raw)\n",
    "\n",
    "# Target Normalizer\n",
    "scaler_target = StandardScaler()\n",
    "scaler_target.fit(y_train_raw)\n",
    "\n",
    "y_train = scaler_target.transform(y_train_raw)\n",
    "y_val = scaler_target.transform(y_val_raw)\n",
    "y_test = scaler_target.transform(y_test_raw)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Verification\n",
    "# --------------------------------------------------\n",
    "print(\"Training shapes:\")\n",
    "print(f\"Signals: {X_sig_train.shape}, Codes: {X_sec_train.shape}, Targets: {y_train.shape}\")\n",
    "print(\"\\nValidation shapes:\")\n",
    "print(f\"Signals: {X_sig_val.shape}, Codes: {X_sec_val.shape}, Targets: {y_val.shape}\")\n",
    "print(\"\\nTest shapes:\")\n",
    "print(f\"Signals: {X_sig_test.shape}, Codes: {X_sec_test.shape}, Targets: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38110ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 208, 2)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 208, 256)             2816      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 208, 256)             1024      ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 104, 256)             0         ['batch_normalization_3[0][0]'\n",
      " g1D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 104, 512)             393728    ['max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 13)]                 0         []                            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 104, 512)             2048      ['conv1d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 13, 16)               16016     ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPoolin  (None, 52, 512)              0         ['batch_normalization_4[0][0]'\n",
      " g1D)                                                               ]                             \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 208)                  0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 52, 1024)             1573888   ['max_pooling1d_3[0][0]']     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 512)                  107008    ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 53248)                0         ['conv1d_5[0][0]']            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 256)                  131328    ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1024)                 5452697   ['flatten_2[0][0]']           \n",
      "                                                          6                                       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 256)                  1024      ['dense_9[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 1024)                 0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 256)                  0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 1280)                 0         ['dropout_2[0][0]',           \n",
      " )                                                                   'dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1024)                 1311744   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 512)                  524800    ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 256)                  131328    ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 6)                    1542      ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58725270 (224.02 MB)\n",
      "Trainable params: 58723222 (224.01 MB)\n",
      "Non-trainable params: 2048 (8.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalMaxPooling1D, Dropout, Embedding, Dot, Softmax\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3.1 Dual Input Branches (Upgraded)\n",
    "# --------------------------------------------------\n",
    "# Branch 1: Radar Signal Processor\n",
    "signal_input = Input(shape=(208, 2))\n",
    "x = Conv1D(256, 5, activation='relu', padding='same')(signal_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(512, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(1024, 3, activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "# this was not at all good for the 15000 samples model\n",
    "\n",
    "# Branch 2: Code Breaker (With Shifted Codes)\n",
    "code_input = Input(shape=(13,))\n",
    "y = Embedding(input_dim=1001, output_dim=16)(code_input)  # Fixed input_dim\n",
    "y = Flatten()(y)\n",
    "y = Dense(512, activation='relu')(y)\n",
    "y = Dense(256, activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dropout(0.3)(y)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3.2 Enhanced Fusion\n",
    "# --------------------------------------------------\n",
    "merged = concatenate([x, y])\n",
    "z = Dense(1024, activation='relu')(merged)\n",
    "z = Dense(512, activation='relu')(z)\n",
    "z = Dense(256, activation='relu')(z)\n",
    "outputs = Dense(6, activation='linear')(z)\n",
    "\n",
    "# Model Compilation\n",
    "model = Model(inputs=[signal_input, code_input], outputs=outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    # Assign higher weights to x, y, z coordinates for both jets\n",
    "    weights = tf.constant([1.2, 1.2, 1.2, 1.2, 1.2, 1.2], dtype=tf.float32)\n",
    "    squared_diff = tf.square(y_true - y_pred)\n",
    "    weighted_squared_diff = squared_diff * weights\n",
    "    return tf.reduce_mean(weighted_squared_diff)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=weighted_mse,\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Reconnaissance Report (Model Summary)\n",
    "# --------------------------------------------------\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8ed786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=0.0001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=20,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < 20:\n",
    "        return 0.0001\n",
    "    elif epoch < 50:\n",
    "        return 0.00005\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38ff814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 165s 437ms/step - loss: 0.9386 - mae: 0.7253 - val_loss: 0.8417 - val_mae: 0.6832 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 166s 442ms/step - loss: 0.7384 - mae: 0.6319 - val_loss: 0.6739 - val_mae: 0.6006 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 153s 407ms/step - loss: 0.7056 - mae: 0.6153 - val_loss: 0.6728 - val_mae: 0.6017 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 151s 404ms/step - loss: 0.6857 - mae: 0.6074 - val_loss: 0.6704 - val_mae: 0.6004 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 173s 460ms/step - loss: 0.6615 - mae: 0.5969 - val_loss: 0.6855 - val_mae: 0.6061 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 170s 453ms/step - loss: 0.6242 - mae: 0.5781 - val_loss: 0.6879 - val_mae: 0.6033 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 174s 464ms/step - loss: 0.5595 - mae: 0.5439 - val_loss: 0.7354 - val_mae: 0.6163 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 168s 447ms/step - loss: 0.4412 - mae: 0.4771 - val_loss: 0.7623 - val_mae: 0.6237 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 168s 447ms/step - loss: 0.3238 - mae: 0.4061 - val_loss: 0.7853 - val_mae: 0.6256 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 163s 435ms/step - loss: 0.2360 - mae: 0.3461 - val_loss: 0.8079 - val_mae: 0.6301 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 166s 442ms/step - loss: 0.1857 - mae: 0.3065 - val_loss: 0.8268 - val_mae: 0.6340 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 181s 484ms/step - loss: 0.1534 - mae: 0.2784 - val_loss: 0.8393 - val_mae: 0.6354 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 175s 466ms/step - loss: 0.1313 - mae: 0.2567 - val_loss: 0.8376 - val_mae: 0.6325 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 171s 455ms/step - loss: 0.1194 - mae: 0.2448 - val_loss: 0.8475 - val_mae: 0.6289 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 164s 438ms/step - loss: 0.1124 - mae: 0.2372 - val_loss: 0.8458 - val_mae: 0.6279 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 161s 428ms/step - loss: 0.1039 - mae: 0.2286 - val_loss: 0.8670 - val_mae: 0.6303 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 175s 465ms/step - loss: 0.1007 - mae: 0.2242 - val_loss: 0.8748 - val_mae: 0.6306 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      " 25/375 [=>............................] - ETA: 2:27 - loss: 0.1020 - mae: 0.2267"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_sig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sec_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use shifted codes\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_sig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sec_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced for better convergence\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_sig_train, X_sec_train],  # Use shifted codes\n",
    "    y_train,\n",
    "    validation_data=([X_sig_val, X_sec_val], y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,  # Reduced for better convergence\n",
    "    callbacks=[early_stop, lr_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42798fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.8911 (Normalized)\n",
      "Test MAE: 0.6348 (Normalized)\n",
      "47/47 [==============================] - 5s 93ms/step\n",
      "Real-World MAE: 5946.05 meters\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(  \n",
    "    [X_sig_test, X_sec_test],   \n",
    "    y_test,  \n",
    "    verbose=0  \n",
    ")  \n",
    "print(f\"Test MSE: {test_loss:.4f} (Normalized)\")  \n",
    "print(f\"Test MAE: {test_mae:.4f} (Normalized)\")  \n",
    "\n",
    "# Inverse-transform for real-world error  \n",
    "y_pred_normalized = model.predict([X_sig_test, X_sec_test])  \n",
    "y_pred_real = scaler_target.inverse_transform(y_pred_normalized)  \n",
    "y_test_real = scaler_target.inverse_transform(y_test)  \n",
    "\n",
    "# Calculate real-world MAE  \n",
    "mae_real = np.mean(np.abs(y_pred_real - y_test_real))  \n",
    "print(f\"Real-World MAE: {mae_real:.2f} meters\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
